

1. Discriminative AI 
    ML 
      1. Recommendation (products, movies)
      2. Classification (dog breed, flower classification)
      3. Prediction (house price next year, weather prediction)
      4. Clustering (grouping -- age, demography, category)
    * output will be deterministic (boolean, string, object, array of object, lists, number, etc)

2. Generative AI 
    LLM 
      generating content (text, code, data, image, audio, video)
    
      * output will be non-deterministic 


Devops 
====
  will deal with code 


MLOps 
===
  deals with code, data, models 



# MLOps Data Versioning Project

This project demonstrates a standard MLOps workflow for data collection and versioning using DVC (Data Version Control) and Git.

It is designed to manage datasets (especially large files or many small files) that are unsuitable for direct tracking in Git, which is a common requirement for RAG knowledge bases, image datasets, and other ML use cases.

The project uses a clean separation between source code (tracked by Git) and datasets (tracked by DVC).

## Project Structure
project_name/
├── .dvc/                  # Auto-generated by DVC
├── .git/                  # Auto-generated by Git
├── data/
│   ├── raw/               # The folder where data lands (DVC tracked)
│   └── .gitignore         # Auto-generated (ignores 'raw/' for Git)
├── scripts/
│   └── fetch_data.py      # Your data collection logic
├── .dvcignore             # Files DVC should ignore
├── .gitignore             # Standard Git ignore
├── Makefile               # Automation for the add/commit loop
└── requirements.txt



## 2. Setup Instructions

### A. Initialize Environment
First, set up your Python virtual environment and install the required packages.


### B. Initialize Version Control
Initialize Git for code versioning and DVC for data versioning.


```
python -m venv venv
source venv/bin/activate # On Windows: venv\Scripts\activate
```
pip install "dvc" 

Install dependencies
```pip install -r requirements.txt```


### B. Initialize Version Control
Initialize Git for code versioning and DVC for data versioning.

Initialize Git repository

```
git init
```
the above step is important.  then only you have to try the following cmd


Initialize DVC
```
dvc init
```


### C. Configure Remote Storage
For this demo, we use a local directory to simulate cloud storage. You can easily swap this with a real S3 bucket, Azure Blob, or Google Drive folder.

Create a local "remote" for DVC to store data
```mkdir /tmp/dvc-storage```

Tell DVC about this remote
```dvc remote add -d localremote /tmp/dvc-storage```

**Note:** To switch to a cloud provider like AWS S3, you would run `dvc remote add -d prod s3://your-bucket-name/folder` and configure your credentials.

## 3. Workflow

The core workflow consists of three simple, repeatable steps: **run**, **save**, and **restore**.

### A. `run`: Fetch New Data
The `fetch_data.py` script simulates fetching a new batch of data and saving it to `data/raw/`.

```make run```


### B. `save`: Snapshot Your Data
The `save` command creates a versioned snapshot of your data. It uses DVC to track the data folder and Git to track the resulting DVC pointer file.

This command is a powerful wrapper that:
1. Adds the `data/raw` folder to DVC's tracking.
2. Adds the updated `data/raw.dvc` pointer file to Git's staging area.
3. Commits the change with your message.
4. Pushes the actual data files to your DVC remote storage (`/tmp/dvc-storage`).


#### Provide a descriptive message for your data change

### C. `restore`: Get a Specific Data Version
If you switch to a different Git branch or commit, the code will change but the data won't—until you tell DVC to sync it. The `restore` command pulls the correct data version from remote storage to match your current Git commit.

This is critical for reproducibility.


